{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b34cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab1a48",
   "metadata": {},
   "source": [
    "# Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b85860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear layer implementation\n",
    "class Linear(object):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(Linear, self).__init__()\n",
    "        # need to know this\n",
    "        self.weight = torch.Tensor(in_feats, out_feats) \n",
    "        self.bias = torch.Tensor(1, out_feats) \n",
    "        # until here\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self, std=0.1):\n",
    "        self.weight = std * torch.randn_like(self.weight)\n",
    "        self.bias = torch.rand_like(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # and this\n",
    "        return torch.matmul(x, self.weight) + self.bias\n",
    "\n",
    "# testing the linear layer\n",
    "n_samples, in_feats, out_feats = 2, 3, 4\n",
    "x = torch.randn((n_samples, in_feats))\n",
    "layer = Linear(in_feats, out_feats)\n",
    "y = layer.forward(x)\n",
    "assert(y.shape == torch.Size([n_samples, out_feats]))\n",
    "\n",
    "# linear layer the pytorch way\n",
    "torch_layer = nn.Linear(in_feats, out_feats)\n",
    "torch_y = torch_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(object):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # also need to know this\n",
    "        return torch.clamp(x, min=0)\n",
    "\n",
    "class Sigmoid(object):\n",
    "    def __init__(self):\n",
    "        super(Sigmoid, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # and this\n",
    "        return 1.0 / (1.0 + torch.exp(-x))\n",
    "\n",
    "# usage\n",
    "y_relu = ReLU().forward(x)\n",
    "y_sigmoid = Sigmoid().forward(x)\n",
    "\n",
    "# the pytorch way\n",
    "torch_relu = nn.ReLU()\n",
    "torch_y_relu = torch_relu(x)\n",
    "torch_sigmoid = nn.Sigmoid()\n",
    "torch_y_sigmoid = torch_sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(object):\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def reset_params(self, std=0.1):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'init_params'):\n",
    "                layer.init_params(std=std)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # need to know this\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "class TorchNet(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_dim, out_feats):\n",
    "        super(TorchNet, self).__init__()\n",
    "        # and this\n",
    "        self.layer1 = nn.Linear(in_feats, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_dim, out_feats)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # and this\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to manually set parameters to a torch layer:\n",
    "# need to know that\n",
    "hidden_dim = 5\n",
    "torch_net = TorchNet(in_feats, hidden_dim, out_feats)\n",
    "torch_net.layer1.weight = nn.Parameter(torch.Tensor(1))  # torch.Tensor is a placeholder here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSELoss(y_true, y_pred):\n",
    "    # need to know this\n",
    "    return torch.mean((y_pred - y_true) ** 2)\n",
    "    # or return (1.0 / len(y_pred)) * torch.sum((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c8a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5119, 1.3014],\n",
      "        [1.0014, 1.0033],\n",
      "        [1.0416, 1.1037],\n",
      "        [1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# toy training loop for the xor problem\n",
    "x_xor = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_xor = torch.tensor([[1, 0], [0, 1], [0, 1], [1, 0]]) # one-hot encoded\n",
    "in_feats, hidden_dim, out_feats = 2, 2, 2\n",
    "layers = [Linear(in_feats, hidden_dim),\n",
    "          ReLU(),\n",
    "          Linear(hidden_dim, out_feats)]\n",
    "net = Net(layers)\n",
    "acc = 0\n",
    "losses = []\n",
    "while acc < 1:\n",
    "    net.reset_params(std=0.5)\n",
    "    y_pred = net.forward(x_xor)\n",
    "    losses.append(MSELoss(y_xor, y_pred))\n",
    "    # calculate accuracy (reverse one-hot with argmax)\n",
    "    acc = torch.sum(y_pred.argmax(1) == y_xor.argmax(1)) / len(y_pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7921e0",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b282e6",
   "metadata": {},
   "source": [
    "**Recap**:\n",
    "$$ y = xw + b $$\n",
    "```\n",
    "                        Linear Layer \n",
    "                  ______________________\n",
    "x -------------> |  w, b, (cache the x) |--------> y\n",
    "                 |        locals        |\n",
    "<---downstream---|______________________|<--upstream\n",
    "\n",
    "```\n",
    "- upstream = $\\frac{\\partial{L}}{\\partial{y}}$\n",
    "- $\\frac{\\partial{y}}{\\partial{w}}=x$ (cached)\n",
    "- $\\frac{\\partial{y}}{\\partial{w}}=1$\n",
    "- locals:\n",
    "  - $\\frac{\\partial{L}}{\\partial{w}}=\\frac{\\partial{L}}{\\partial{y}}\\cdot \\frac{\\partial{y}}{\\partial{w}}=$ upstream $\\cdot x$\n",
    "  - $\\frac{\\partial{L}}{\\partial{b}}=\\frac{\\partial{L}}{\\partial{y}}\\cdot \\frac{\\partial{y}}{\\partial{b}}=$ upstream $\\cdot 1$\n",
    "- downstream = $\\frac{\\partial{L}}{\\partial{x}}=\\frac{\\partial{L}}{\\partial{y}}\\cdot \\frac{\\partial{y}}{\\partial{x}}=$ upstream $\\cdot w$ (the message that needs to be passed upwards according to the backprop algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842974c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(Linear, self).__init__()\n",
    "        self.weight = torch.Tensor(in_feats, out_feats)\n",
    "        self.bias = torch.Tensor(out_feats)\n",
    "        self.init_params()\n",
    "        self.cache = None\n",
    "        self.weight_grad = None\n",
    "        self.bias_grad = None\n",
    "    \n",
    "    def init_params(self, std=0.1):\n",
    "        self.weight = std * torch.randn_like(self.weight)\n",
    "        self.bias = torch.rand_like(self.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = torch.matmul(x, self.weight) + self.bias\n",
    "        # know this caching\n",
    "        self.cache = x\n",
    "        return y \n",
    "    \n",
    "    def backward(self, dupstream):\n",
    "        # and these\n",
    "        self.weight_grad = torch.matmul(self.cache.T, dupstream)\n",
    "        self.bias_grad = torch.sum(dupstream, dim=0)\n",
    "        dx = torch.matmul(dupstream, self.weight.T)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(object):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = torch.clamp(x, min=0)\n",
    "        # know this - cache the activation not the input!\n",
    "        self.cache = y\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dupstream):\n",
    "        # know these\n",
    "        dx = dupstream.clone() # make sure we don't modify the upstream\n",
    "        dx[self.cache == 0] = 0\n",
    "        return dx\n",
    "\n",
    "class Sigmoid(object):\n",
    "    def __init__(self):\n",
    "        super(Sigmoid, self).__init__()\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = 1.0 / (1.0 + torch.exp(-x))\n",
    "        # know this - cache the activation, not the input!\n",
    "        self.cache = y\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dupstream):\n",
    "        # know this\n",
    "        return dupstream * self.cache * (1 - self.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a30abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the torch way\n",
    "x.requires_grad = True\n",
    "torch_y = torch_layer(x)\n",
    "torch_y.backward(dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(object):\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self, std=1.):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'init_params'):\n",
    "                layer.init_params(std=std)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dupstream):\n",
    "        # know this\n",
    "        dx = dupstream\n",
    "        for layer in reversed(self.layers):\n",
    "            dx = layer.backward(dx)\n",
    "        return dx\n",
    "    \n",
    "    def optimizer_step(self, lr):\n",
    "        # know this\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'weight'):\n",
    "                layer.weight -= lr * layer.weight_grad\n",
    "            if hasattr(layer, 'bias'):\n",
    "                layer.bias -= lr * layer.bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb535916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSELoss(y_true, y_pred):\n",
    "    loss = torch.mean((y_pred - y_true) ** 2)\n",
    "    # know this\n",
    "    grad = 2 * (y_pred - y_true) # dL/dy_pred\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9096, 0.0114],\n",
      "        [0.1047, 0.9534],\n",
      "        [0.0541, 0.9737],\n",
      "        [0.9306, 0.0456]])\n"
     ]
    }
   ],
   "source": [
    "# revisiting the xor problem and the training loop\n",
    "x_xor = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_xor = torch.tensor([[1, 0], [0, 1], [0, 1], [1, 0]]) # one-hot encoded\n",
    "in_features, hidden_dim, out_features = 2, 10, 2\n",
    "learning_rate = 1e-2\n",
    "optim_steps = 100\n",
    "layers = [Linear(in_features, hidden_dim),\n",
    "          ReLU(),\n",
    "          Linear(hidden_dim, out_features)]\n",
    "net = Net(layers)\n",
    "losses = []\n",
    "accs = []\n",
    "for i in range(optim_steps):\n",
    "    y_pred = net.forward(x_xor)\n",
    "    # know from here\n",
    "    loss, grad = MSELoss(y_xor, y_pred)\n",
    "    losses.append(loss)\n",
    "    net.backward(grad)\n",
    "    net.optimizer_step(learning_rate)\n",
    "    # to here\n",
    "    correct = torch.argmax(y_pred, axis=1) == torch.argmax(y_xor, axis=1)\n",
    "    accs.append(torch.sum(correct)/len(y_pred))\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softmax(z):\n",
    "    # know this\n",
    "    e = torch.exp(z)\n",
    "    return e / torch.sum(e, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't need to know the implementation of this\n",
    "def CrossEntropyLoss(y_true, y_pred):\n",
    "    softmax = Softmax(y_pred)\n",
    "    y_true = torch.argmax(y_true, axis=1)\n",
    "    n = y_true.shape[0]\n",
    "    log_likelihood = -torch.log(softmax[torch.arange(n),y_true])\n",
    "    loss = torch.mean(log_likelihood)\n",
    "    \n",
    "    grad = softmax\n",
    "    softmax[torch.arange(n), y_true] -= 1\n",
    "    grad /= n\n",
    "    \n",
    "    return loss, grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3f96e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73da3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you only need to know the shapes here and the feedforward part\n",
    "class Conv2d(object):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.weight = torch.Tensor(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        self.bias = torch.Tensor(out_channels)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self, std=0.7071):  # why 1 / sqrt(2) ?\n",
    "        self.weight = std * torch.randn_like(self.weight)\n",
    "        self.bias = torch.rand_like(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # dims of x: (N, C, H, W)\n",
    "        x_padded = torch.nn.functional.pad(x, [self.padding] * 4) \n",
    "        N, _, H, W = x.shape\n",
    "        Hp = 1 + (H + 2 * self.padding - self.kernel_size) // self.stride\n",
    "        Wp = 1 + (W + 2 * self.padding - self.kernel_size) // self.stride\n",
    "        y = torch.empty((N, self.out_channels, Hp, Wp), dtype=x.dtype, device=x.device)\n",
    "        # you need to know the part below\n",
    "        for i in range(Hp):\n",
    "            for j in range(Wp):\n",
    "                h_offset = i * self.stride\n",
    "                w_offset = j * self.stride\n",
    "                window = x_padded[:, :, h_offset:h_offset+self.kernel_size, w_offset:w_offset+self.kernel_size]\n",
    "                for k in range(N):\n",
    "                    y[k, :, i, j] = torch.sum(window[k] * self.weight, dim=(1, 2, 3)) + self.bias\n",
    "        # until here\n",
    "        self.cache = x_padded\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dupstream):\n",
    "        x_padded = self.cache\n",
    "        dx_padded = torch.zeros_like(x_padded)\n",
    "        self.weight_grad = torch.zeros_like(self.weight)\n",
    "        N, _, Hp, Wp = dupstream.shape\n",
    "        for i in range(Hp):\n",
    "            for j in range(Wp):\n",
    "                h_offset = i * self.stride\n",
    "                w_offset = j * self.stride\n",
    "                window = x_padded[:, :, h_offset:h_offset+self.kernel_size, w_offset:w_offset+self.kernel_size]\n",
    "                dwindow = dx_padded[:, :, h_offset:h_offset+self.kernel_size, w_offset:w_offset+self.kernel_size]\n",
    "                for k in range(N):\n",
    "                    dwindow[k] += (self.weight * dupstream[k, :, i, j].view(-1, 1, 1, 1)).sum(dim=0)\n",
    "                    self.weight_grad += window[k].view(1, self.in_channels, self.kernel_size, self.kernel_size) * dupstream[k, :, i, j].view(-1, 1, 1, 1)\n",
    "        H = x_padded.shape[2] - 2 * self.padding\n",
    "        W = x_padded.shape[3] - 2 * self.padding\n",
    "        dx = dx_padded[:, :, self.padding:self.padding+H, self.padding:self.padding+W]\n",
    "        self.bias_grad = dupstream.sum(dim=(0, 2, 3))\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc871bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d(object):\n",
    "    def __init__(self, kernel_size, stride=1, padding=0):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_padded = torch.nn.functional.pad(x, [self.padding] * 4)\n",
    "        N, C, H, W = x.shape\n",
    "        KS = self.kernel_size\n",
    "        Hp = 1 + (H + 2 * self.padding - KS) // self.stride\n",
    "        Wp = 1 + (W + 2 * self.padding - KS) // self.stride\n",
    "        y = torch.empty((N*C, Hp, Wp), dtype=x.dtype, device=x.device)\n",
    "        # part you should know - begin\n",
    "        for i in range(Hp):\n",
    "            for j in range(Wp):\n",
    "                h_offset = i * self.stride\n",
    "                w_offset = j * self.stride\n",
    "                window = x_padded[:, :, h_offset:h_offset+self.kernel_size, w_offset:w_offset+self.kernel_size]\n",
    "                window = window.reshape(N * C, -1)\n",
    "                y[:, i, j] = window.max(dim=1).values\n",
    "        # end\n",
    "        y = y.reshape(N, C, Hp, Wp)\n",
    "        self.cache = x\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dupstream):\n",
    "        x = self.cache\n",
    "        dx = torch.zeros_like(x)\n",
    "        N, C, Hp, Wp = dupstream.shape\n",
    "        for i in range(Hp):\n",
    "            for j in range(Wp):\n",
    "                h_offset = i * self.stride\n",
    "                w_offset = j * self.stride\n",
    "                window = x[:, :, h_offset:h_offset+self.kernel_size, w_offset:w_offset+self.kernel_size].reshape(N*C, -1)\n",
    "                indices = window.argmax(dim=1)\n",
    "                dwindow = torch.zeros_like(window)\n",
    "                dwindow[torch.arange(N*C), indices] += dupstream[:, :, i, j].view(-1)\n",
    "                dx[:, :, h_offset:h_offset+self.kernel_size, w_offset:w_offset+self.kernel_size] += dwindow.reshape(N, C, self.kernel_size, self.kernel_size)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42017050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layers with dimensions\n",
    "n_samples, height, width, in_channels = 1, 16, 16, 3\n",
    "hidden_channels, out_features = [5, 6], 2\n",
    "\n",
    "layers = [\n",
    "    Conv2d(in_channels, hidden_channels[0], kernel_size=3, padding=1),\n",
    "    ReLU(),\n",
    "    Conv2d(hidden_channels[0], hidden_channels[1], kernel_size=5, padding=2),\n",
    "    ReLU(),\n",
    "    Linear(16*16*hidden_channels[1], out_features)  # !\n",
    "\n",
    "]\n",
    "\n",
    "# with torch\n",
    "class TorchCNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_feats):\n",
    "        super(TorchCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels[0], kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(hidden_channels[0], hidden_channels[1], kernel_size=5, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc = nn.Linear(16 * 16 * hidden_channels[1], out_feats)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = x.flatten(1) # !\n",
    "        x = self.fc(x)\n",
    "\n",
    "# Q: how many params?\n",
    "# A: 140 + 0 + 756 + 0 + 3074 = 3970"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf70c0",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818df1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWMA update\n",
    "s_prev = 0\n",
    "s_cur = rho * s_prev + (1 - rho) * y\n",
    "# EWMA with bias correction\n",
    "s_cur_bc = s_cur / (1 - rho**(i + 1)) # i+1 !\n",
    "\n",
    "# GD with momentum\n",
    "v = rho * v_prev + (1 - rho) * gradient\n",
    "X = X - learning_rate * v\n",
    "\n",
    "# RMSProp\n",
    "r = rho * r_prev + (1 - rho) * gradient**2\n",
    "X = X - (learning_rate / np.sqrt(r + delta)) * gradient\n",
    "\n",
    "# Adam\n",
    "v = rho_v * v_prev + (1 - rho_v) * gradient\n",
    "v_bc = v / (1 + rho_v**index)\n",
    "r = rho_r * r_prev + (1 - rho_r) * gradient**2\n",
    "r_bc = r / (1 - rho_r**index)\n",
    "X = X - (learning_rate / np.sqrt(r_bc + delta)) * v_bc # do not forget the delta !\n",
    "\n",
    "# Torch\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=5e-2, momentum=0.9)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc08a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical training loop (not sure if they want us to know that)\n",
    "def train(train_loader, net, optimizer, criterion):\n",
    "    avg_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return avg_loss/len(train_loader), 100 * correct / total\n",
    "        \n",
    "def test(test_loader, net, criterion):\n",
    "    avg_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            avg_loss += loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return avg_loss/len(test_loader), 100 * correct / total\n",
    "\n",
    "writer = SummaryWriter()\n",
    "epochs = 100\n",
    "net = FCNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=5e-1)\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    train_loss, train_acc = train(train_loader, net, optimizer, criterion)\n",
    "    test_loss, test_acc = test(test_loader, net, criterion)\n",
    "    writer.add_scalars(\"Loss\", {'Train': train_loss, 'Test':test_loss}, epoch)            \n",
    "    writer.add_scalars('Accuracy', {'Train': train_acc, 'Test':test_acc} , epoch)\n",
    "\n",
    "print('Finished Training')\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293962b",
   "metadata": {},
   "source": [
    "# Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7dd6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularization (L = L_0 + (lambda / 2)*sum(w**2))\n",
    "l2 = 0\n",
    "for p in net.parameters():\n",
    "    l2 += torch.sum(p**2)\n",
    "loss += 0.5 * wd * l2 # wd is the weight decay (L2 penalty)\n",
    "\n",
    "# the torch way:\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=5e-2, weight_decay=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ffb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "patience = 0\n",
    "val_acc_best = 0\n",
    "patience_cnt = 0\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(train_loader, net, optimizer, criterion)\n",
    "    val_loss, val_acc = test(val_loader, net, criterion)\n",
    "    # this part\n",
    "    if val_acc > val_acc_best:\n",
    "        patience_cnt = 0\n",
    "        val_acc_best = val_acc\n",
    "    else:\n",
    "        patience_cnt += 1\n",
    "        if patience_cnt == patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37196252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout\n",
    "self.do = nn.Dropout(p=0.4) # 40% neurons activated (the rest are set to zero)\n",
    "\n",
    "# six fully-connected layers with residual connection and dropout layers\n",
    "self.fc1 = nn.Linear(40, 500)\n",
    "...\n",
    "self.fc6 = nn.Linear(500, 10)\n",
    "\n",
    "h = F.relu(self.fc1(x))\n",
    "h = h + F.relu(self.fc2(h))\n",
    "h = self.do1(h)\n",
    "h = h + F.relu(self.fc3(h))\n",
    "h = h + F.relu(self.fc4(h))\n",
    "h = self.do2(h)\n",
    "h = h + F.relu(self.fc5(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c972c",
   "metadata": {},
   "source": [
    "# Recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elman (vanilla) RNN\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_xh = None\n",
    "        self.weight_hh = None\n",
    "        self.bias_xh = None\n",
    "        self.bias_hh = None\n",
    "\n",
    "        # need to know this\n",
    "        self.weight_xh = nn.Parameter(torch.Tensor(input_size, hidden_size)) # input_size = D\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.bias_xh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        self.bias_hh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        # until here\n",
    "\n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        self.weight_xh.data.uniform_(-std, std)\n",
    "        self.weight_hh.data.uniform_(-std, std)\n",
    "        self.bias_xh.data.uniform_(-std, std)\n",
    "        self.bias_hh.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # X (N, T, D) = (samples, timestep, input size)\n",
    "        x = x.transpose(0, 1) # (T, N, D) after transposing\n",
    "        T, N = x.shape[0], x.shape[1]\n",
    "        h0 = torch.zeros(N, self.hidden_size, device=x.device)\n",
    "        y = []\n",
    "\n",
    "        # need to know this\n",
    "        # ht​ = tanh(W_xh * ​xt ​+ b_xh ​+ W_hh * ​h(t−1) ​+ b_hh​)\n",
    "        ht_1 = h0\n",
    "        for t in range(T):\n",
    "            xh = torch.addmm(self.bias_xh, x[t], self.weight_xh)\n",
    "            hh = torch.addmm(self.bias_hh, ht_1, self.weight_hh)\n",
    "            ht = torch.tanh(xh + hh)\n",
    "            y.append(ht)\n",
    "            ht_1 = ht\n",
    "        # until here\n",
    "\n",
    "        y = torch.stack(y)\n",
    "        y = y.transpose(0, 1) # (T, N, H)\n",
    "        # y (N, T, H) after transposing\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_xh = None\n",
    "        self.weight_hh = None\n",
    "        self.bias_xh = None\n",
    "        self.bias_hh = None\n",
    "\n",
    "        # need to know the dimensions\n",
    "        self.weight_xh = nn.Parameter(torch.Tensor(input_size, 3 * hidden_size)) # r, z, n concatenated\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(hidden_size, 3 * hidden_size))\n",
    "        self.bias_xh = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "        self.bias_hh = nn.Parameter(torch.Tensor(3 * hidden_size))\n",
    "\n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        self.weight_xh.data.uniform_(-std, std)\n",
    "        self.weight_hh.data.uniform_(-std, std)\n",
    "        self.bias_xh.data.uniform_(-std, std)\n",
    "        self.bias_hh.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(0, 1)\n",
    "        T, N, H = x.shape[0], x.shape[1], self.hidden_size\n",
    "        h0 = torch.zeros(N, H, device=x.device)\n",
    "        y = []\n",
    "\n",
    "        # part that you should know below\n",
    "        # rt​ = σ(W_xr * ​xt​ + b_xr​ + W_hr * ​h(t−1) ​+ b_hr​)\n",
    "        # zt​ = σ(W_xz * ​xt​ + b_xz​ + W_hz * ​h(t−1) ​+ b_hz​)\n",
    "        # nt​ = tanh(W_xn * ​xt ​+ b_xn ​+ rt​(W_hn * ​h(t−1) ​+ b_hn​))\n",
    "        # ht​ = (1 − zt​) ⊙ nt ​+ zt​ ⊙ h(t−1)​\n",
    "        ht_1 = h0\n",
    "        for t in range(T):\n",
    "            xh = torch.addmm(self.bias_xh, x[t], self.weight_xh) \n",
    "            hh = torch.addmm(self.bias_hh, ht_1, self.weight_hh)\n",
    "            rt = torch.sigmoid(xh[:, 0:H] + hh[:, 0:H])\n",
    "            zt = torch.sigmoid(xh[:, H:2*H] + hh[:, H:2*H])\n",
    "            nt = torch.tanh(xh[:, 2*H:3*H] + rt*hh[:, 2*H:3*H])\n",
    "            ht = (1 - zt) * nt + zt * ht_1\n",
    "            y.append(ht)\n",
    "            ht_1 = ht\n",
    "        # until here\n",
    "\n",
    "        y = torch.stack(y)\n",
    "        y = y.transpose(0, 1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddeed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_xh = None\n",
    "        self.weight_hh = None\n",
    "        self.bias_xh = None\n",
    "        self.bias_hh = None\n",
    "\n",
    "        # need to know this\n",
    "        self.weight_xh = nn.Parameter(torch.Tensor(input_size, 4*hidden_size))\n",
    "        self.weight_hh = nn.Parameter(torch.Tensor(hidden_size, 4*hidden_size))\n",
    "        self.bias_xh = nn.Parameter(torch.Tensor(4*hidden_size))\n",
    "        self.bias_hh = nn.Parameter(torch.Tensor(4*hidden_size))\n",
    "\n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        self.weight_xh.data.uniform_(-std, std)\n",
    "        self.weight_hh.data.uniform_(-std, std)\n",
    "        self.bias_xh.data.uniform_(-std, std)\n",
    "        self.bias_hh.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(0, 1)  # (N, T, D) -> (T, N, D)\n",
    "        T, N, H = x.shape[0], x.shape[1], self.hidden_size\n",
    "        h0 = torch.zeros(N, H, device=x.device)\n",
    "        c0 = torch.zeros(N, H, device=x.device)\n",
    "        y = []\n",
    "\n",
    "        # it ​= σ(W_xi * ​xt ​+ b_xi ​+ W_hi * ​h(t−1) ​+ b_hi​)\n",
    "        # ft​ = σ(W_xf * ​xt ​+ b_xf ​+ W_hf * ​h(t−1) ​+ b_hf​)\n",
    "        # gt ​= tanh(W_xg * ​xt ​+ b_xg ​+ W_hg * ​h(t−1) ​+ b_hg​)\n",
    "        # ot ​= σ(W_xo * ​xt ​+ b_xo​ + W_ho ​h(t−1) ​+ b_ho​)\n",
    "        # ct ​= ft​ ⊙ c(t−1) ​+ it ​⊙ gt​\n",
    "        # ht ​= ot​ ⊙ tanh(ct​)​\n",
    "        # ht_1 = h0\n",
    "        ct_1 = c0\n",
    "        ht_1 = h0\n",
    "        for t in range(T):\n",
    "            xh = torch.addmm(self.bias_xh, x[t], self.weight_xh) \n",
    "            hh = torch.addmm(self.bias_hh, ht_1, self.weight_hh)\n",
    "            it = torch.sigmoid(xh[:, 0:H] + hh[:, 0:H])\n",
    "            ft = torch.sigmoid(xh[:, H:2*H] + hh[:, H:2*H])\n",
    "            gt = torch.tanh(xh[:, 2*H:3*H] + hh[:, 2*H:3*H])\n",
    "            ot = torch.sigmoid(xh[:, 3*H:4*H] + hh[:, 3*H:4*H])\n",
    "            ct = ft * ct_1 + it * gt\n",
    "            ht = ot * torch.tanh(ct) # ct! and don't forget the tanh\n",
    "            y.append(ht)\n",
    "            ct_1 = ct\n",
    "            ht_1 = ht\n",
    "\n",
    "        y = torch.stack(y)\n",
    "        y = y.transpose(0, 1) # (T, N, H) -> (N, T, H)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988a744c",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc42e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must know this\n",
    "class BasicSelfAttention(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # dimensions of x: (b, t, k) (batch size, sequence length, embedding dimension)\n",
    "        w_prime = torch.bmm(x, x.transpose(1, 2))\n",
    "        w = F.softmax(w_prime, dim=2)  # sum over the sequences not over vector!\n",
    "        y = torch.bmm(w, x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8eed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, k):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.tokeys    = nn.Linear(k, k, bias=False)\n",
    "        self.toqueries = nn.Linear(k, k, bias=False)\n",
    "        self.tovalues  = nn.Linear(k, k, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, k = x.size()\n",
    "        # you must know this\n",
    "        queries = self.toqueries(x)\n",
    "        keys = self.tokeys(x)\n",
    "        values = self.tovalues(x)\n",
    "        w_prime = torch.bmm(queries, keys.transpose(1, 2)) # !\n",
    "        w_prime = w_prime / (k**0.5)\n",
    "        w = F.softmax(w_prime, dim=2)\n",
    "        y = torch.bmm(w, values) # !\n",
    "        # until here\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ec7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide multi-head attention layer\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, k, heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = heads\n",
    "        self.tokeys    = nn.Linear(k, k * heads, bias=False)\n",
    "        self.toqueries = nn.Linear(k, k * heads, bias=False)\n",
    "        self.tovalues  = nn.Linear(k, k * heads, bias=False)\n",
    "        self.unifyheads = nn.Linear(k * heads, k)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, t, k = x.size()\n",
    "        h = self.heads\n",
    "        # must know all this\n",
    "        queries = self.toqueries(x).view(b, t, h, k)\n",
    "        keys = self.tokeys(x).view(b, t, h, k)\n",
    "        values = self.tovalues(x).view(b, t, h, k)\n",
    "        queries = queries.transpose(1, 2).reshape(b * h, t, k)  # fold heads into the batch dim\n",
    "        keys = keys.transpose(1, 2).reshape(b * h, t, k)\n",
    "        values = values.transpose(1, 2).reshape(b * h, t, k)\n",
    "        w_prime = torch.bmm(queries, keys.transpose(1, 2)) / (k ** 0.5) # compute attention weights\n",
    "        w = F.softmax(w_prime, dim=2)\n",
    "        y = torch.bmm(w, values).view(b, h, t, k) # apply self-attention to the values\n",
    "        y = y.transpose(1, 2).reshape(b, t, h * k) # swap h, t back, unify heads\n",
    "        y = self.unifyheads(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854fb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, k, heads):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(k, heads=heads)\n",
    "        self.norm1 = nn.LayerNorm(k)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(k, 4 * k),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * k, k)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(k)\n",
    "    def forward(self, x):\n",
    "        # need to know this\n",
    "        att = self.att(x)\n",
    "        res1 = x + att\n",
    "        norm1 = self.norm1(res1)\n",
    "        ff = self.ff(norm1)\n",
    "        res2 = ff + norm1\n",
    "        y = self.norm2(res2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c201a22",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dims, s_img, hdim):\n",
    "        super(Encoder, self).__init__()\n",
    "        # know these\n",
    "        self.linear1 = nn.Linear(s_img * s_img, hdim[0])\n",
    "        self.linear2 = nn.Linear(hdim[0], hdim[1])\n",
    "        self.linear3 = nn.Linear(hdim[1], latent_dims)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # and these\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x) # no activation!\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims, s_img, hdim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(latent_dims, hdim[1])\n",
    "        self.linear2 = nn.Linear(hdim[1], hdim[0])\n",
    "        self.linear3 = nn.Linear(hdim[0], s_img*s_img)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # and these\n",
    "        z = self.relu(self.linear1(z))\n",
    "        z = self.relu(self.linear2(z))\n",
    "        z = self.sigmoid(self.linear3(z))\n",
    "        z = z.reshape((-1, 1, s_img, s_img))\n",
    "        return z\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dims, s_img, hdim = [100, 50]):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(latent_dims, s_img, hdim)\n",
    "        self.decoder = Decoder(latent_dims, s_img, hdim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # and these\n",
    "        z = self.encoder(x)\n",
    "        y = self.decoder(z)\n",
    "        return y\n",
    "\n",
    "# when you train this, use MSE loss, not CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f02123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarEncoder(nn.Module):\n",
    "    def __init__(self, latent_dims, s_img, hdim):\n",
    "        super(VarEncoder, self).__init__()\n",
    "        self.linear1_1 = nn.Linear(s_img*s_img, hdim[0])\n",
    "        self.linear2_1 = nn.Linear(hdim[0], hdim[1])\n",
    "        self.linear3_1 = nn.Linear(hdim[1], latent_dims)\n",
    "        \n",
    "        self.linear1_2 = nn.Linear(s_img*s_img, hdim[0])\n",
    "        self.linear2_2 = nn.Linear(hdim[0], hdim[1])\n",
    "        self.linear3_2 = nn.Linear(hdim[1], latent_dims)\n",
    "        self.relu    = nn.ReLU()\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.N.loc = self.N.loc.to(try_gpu()) # hack to get sampling on the GPU\n",
    "        self.N.scale = self.N.scale.to(try_gpu())\n",
    "        self.kl = 0\n",
    "\n",
    "    # need to know this\n",
    "    def kull_leib(self, mu, sig): # the KL loss is added to the loss during training\n",
    "        return (sig**2 + mu**2 - torch.log(sig) - 1/2).sum()\n",
    "\n",
    "    # and this\n",
    "    def reparameterize(self, mu, sig):\n",
    "        return mu + sig * self.N.sample(mu.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # and all this\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        sig = self.relu(self.linear1_1(x))\n",
    "        sig = self.relu(self.linear2_1(sig))\n",
    "        sig = self.linear3_1(sig)\n",
    "\n",
    "        sig = torch.exp(sig)  # <-- sigma needs exp too for some reason?\n",
    "\n",
    "        mu = self.relu(self.linear1_2(x))\n",
    "        mu = self.relu(self.linear2_2(mu))\n",
    "        mu = self.linear3_2(mu)\n",
    "        # until here\n",
    "        z = self.reparameterize(mu, sig)\n",
    "        self.kl = self.kull_leib(mu, sig)\n",
    "        return z\n",
    "\n",
    "class VarAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dims, s_img, hdim = [100, 50]):\n",
    "        super(VarAutoencoder, self).__init__()\n",
    "        self.encoder = VarEncoder(latent_dims, s_img, hdim)\n",
    "        self.decoder = Decoder(latent_dims, s_img, hdim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        y = self.decoder(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d1af1",
   "metadata": {},
   "source": [
    "# Other notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accecccd",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Suppose we have:\n",
    "```\n",
    "X = torch.Tensor([\n",
    "    [ [[2, 3]], [[5, 7]], [[11, 13]], [[17, 19]] ],\n",
    "    [ [[0, 1]], [[1, 2]], [[3, 5]], [[8, 13]] ],\n",
    "    [ [[1, 2]], [[3, 4]], [[5, 6]], [[7, 8]] ]\n",
    "])\n",
    "```\n",
    "\n",
    "The shape of X is (3, 4, 1, 2) (essentially Batch, Channel, Height, Width)\n",
    "\n",
    "Normalization: $x_i := \\frac{x_i - m_i}{\\sqrt{s^2 + e}}$, where e is a small value to prevent division by zero)\n",
    "\n",
    "Batch Normalization: (per channel)\n",
    "$m_i = mean(2, 3, 0, 1, 1, 2)$\n",
    "$s_i^2 = var(2, 3, 0, 1, 1, 2)$\n",
    "\n",
    "Layer Normalization: (per batch) (independent of batch size, and of other features in a batch)\n",
    "$m_i = mean(2, 3, 5, 7, 11, 13, 17, 19)$\n",
    "$s_i^2 = var(2, 3, 5, 7, 11, 13, 17, 19)$\n",
    "\n",
    "Instance Normalization: (per feature/height-width) (like Batch-Norm w/ batch size 1 - not really used)\n",
    "$m_i = mean(2, 3)$\n",
    "$s_i^2 = var(2, 3)$\n",
    "\n",
    "Group Normalization: (like Layer Norm but with groups)\n",
    "$m_i = mean(2, 3, 5, 7)$\n",
    "$s_i^2 = var(2, 3, 5, 7)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f450e4",
   "metadata": {},
   "source": [
    "## How to avoid vanishing/exploding gradients\n",
    "\n",
    "- Use ReLu-like activation functions (ReLU, Leaky-ReLu, Randomized ReLu etc)\n",
    "- Use Batch Normalization (BN) (or GN, especially when using sigmoid or tanh)\n",
    "- Add residual connections (\"highways\" for gradients to flow backwards unchanged)\n",
    "- Try a smaller learning rate\n",
    "- Use proper weight initialization\n",
    "- You can try gradient clipping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
